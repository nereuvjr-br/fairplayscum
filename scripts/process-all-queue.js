#!/usr/bin/env node

const BATCH_SIZE = 5; // Processar 5 por vez
const DELAY_BETWEEN_BATCHES = 35000; // 35 segundos entre batches

async function processBatch() {
  try {
    console.log(`â³ Processando batch de atÃ© ${BATCH_SIZE} consultas...`);
    
    const response = await fetch(`http://localhost:3000/api/steam/process-batch?batch=${BATCH_SIZE}`);
    const data = await response.json();

    if (data.success) {
      console.log(`âœ… ${data.processed} consultas processadas`);
      
      data.results.forEach((result) => {
        if (result.processed) {
          console.log(`   âœ“ ${result.steamid} - ${result.queryType}`);
        } else if (result.error) {
          console.log(`   âœ— Erro: ${result.error}`);
        } else {
          console.log(`   â„¹ ${result.message}`);
        }
      });

      return data.processed;
    } else {
      console.error("âŒ Erro:", data.error);
      return 0;
    }
  } catch (error) {
    console.error("âŒ Erro ao processar batch:", error.message);
    return 0;
  }
}

async function processAll() {
  console.log("ðŸš€ Iniciando processamento de todas as consultas pendentes...\n");

  let totalProcessed = 0;
  let continueProcessing = true;

  while (continueProcessing) {
    const processed = await processBatch();
    totalProcessed += processed;

    if (processed === 0) {
      continueProcessing = false;
      console.log("\nâœ… Todas as consultas foram processadas!");
    } else {
      console.log(`\nâ³ Aguardando ${DELAY_BETWEEN_BATCHES / 1000}s antes do prÃ³ximo batch...\n`);
      await new Promise(resolve => setTimeout(resolve, DELAY_BETWEEN_BATCHES));
    }
  }

  console.log(`\nðŸ“Š Total processado: ${totalProcessed} consultas`);
}

processAll();
